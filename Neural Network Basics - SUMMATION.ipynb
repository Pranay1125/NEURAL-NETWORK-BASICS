{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1=[]\n",
    "d2=[]\n",
    "d3=[]\n",
    "for i in range(50000):\n",
    "    x=random.random()\n",
    "    d1.append(x)\n",
    "    y=random.random()\n",
    "    d2.append(y)\n",
    "    d3.append(x+y)\n",
    "    \n",
    "# Initializing dependent and independent(target) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059411</td>\n",
       "      <td>0.834607</td>\n",
       "      <td>0.894018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.870221</td>\n",
       "      <td>0.491276</td>\n",
       "      <td>1.361497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.801795</td>\n",
       "      <td>0.232707</td>\n",
       "      <td>1.034501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.816664</td>\n",
       "      <td>0.913883</td>\n",
       "      <td>1.730548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.117772</td>\n",
       "      <td>0.621719</td>\n",
       "      <td>0.739491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3\n",
       "0  0.059411  0.834607  0.894018\n",
       "1  0.870221  0.491276  1.361497\n",
       "2  0.801795  0.232707  1.034501\n",
       "3  0.816664  0.913883  1.730548\n",
       "4  0.117772  0.621719  0.739491"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'x1':d1,'x2':d2,'x3':d3},index=range(0,50000))\n",
    "df.head()\n",
    "# Taking the variables in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             x1        x2\n",
      "0      0.059411  0.834607\n",
      "1      0.870221  0.491276\n",
      "2      0.801795  0.232707\n",
      "3      0.816664  0.913883\n",
      "4      0.117772  0.621719\n",
      "5      0.503689  0.767945\n",
      "6      0.365743  0.578018\n",
      "7      0.162220  0.631907\n",
      "8      0.095921  0.002349\n",
      "9      0.436816  0.072943\n",
      "10     0.434769  0.528028\n",
      "11     0.481297  0.559473\n",
      "12     0.434310  0.836751\n",
      "13     0.920640  0.039686\n",
      "14     0.527959  0.635921\n",
      "15     0.003798  0.691879\n",
      "16     0.864083  0.341574\n",
      "17     0.923065  0.299214\n",
      "18     0.924556  0.939868\n",
      "19     0.515099  0.518086\n",
      "20     0.448509  0.346903\n",
      "21     0.800368  0.319255\n",
      "22     0.569277  0.653428\n",
      "23     0.250729  0.357096\n",
      "24     0.464663  0.664947\n",
      "25     0.003128  0.179488\n",
      "26     0.761388  0.181988\n",
      "27     0.804965  0.657761\n",
      "28     0.555238  0.815213\n",
      "29     0.644794  0.344877\n",
      "...         ...       ...\n",
      "49970  0.418122  0.235569\n",
      "49971  0.426942  0.019889\n",
      "49972  0.594112  0.653001\n",
      "49973  0.105142  0.214399\n",
      "49974  0.516534  0.570724\n",
      "49975  0.025462  0.125615\n",
      "49976  0.643702  0.617919\n",
      "49977  0.040278  0.498808\n",
      "49978  0.872099  0.342075\n",
      "49979  0.016968  0.418043\n",
      "49980  0.415071  0.446631\n",
      "49981  0.026560  0.053389\n",
      "49982  0.617999  0.730424\n",
      "49983  0.149358  0.539961\n",
      "49984  0.036136  0.717884\n",
      "49985  0.374167  0.270826\n",
      "49986  0.736898  0.478393\n",
      "49987  0.277973  0.194999\n",
      "49988  0.777444  0.407528\n",
      "49989  0.130332  0.183894\n",
      "49990  0.295368  0.408525\n",
      "49991  0.731430  0.241328\n",
      "49992  0.364569  0.648336\n",
      "49993  0.525091  0.230483\n",
      "49994  0.403930  0.052720\n",
      "49995  0.938351  0.957410\n",
      "49996  0.969634  0.914975\n",
      "49997  0.285556  0.313633\n",
      "49998  0.887150  0.605116\n",
      "49999  0.552126  0.695910\n",
      "\n",
      "[50000 rows x 2 columns]\n",
      "0        0.894018\n",
      "1        1.361497\n",
      "2        1.034501\n",
      "3        1.730548\n",
      "4        0.739491\n",
      "5        1.271634\n",
      "6        0.943762\n",
      "7        0.794127\n",
      "8        0.098270\n",
      "9        0.509759\n",
      "10       0.962797\n",
      "11       1.040770\n",
      "12       1.271061\n",
      "13       0.960326\n",
      "14       1.163880\n",
      "15       0.695677\n",
      "16       1.205658\n",
      "17       1.222278\n",
      "18       1.864424\n",
      "19       1.033185\n",
      "20       0.795413\n",
      "21       1.119623\n",
      "22       1.222706\n",
      "23       0.607825\n",
      "24       1.129611\n",
      "25       0.182616\n",
      "26       0.943376\n",
      "27       1.462726\n",
      "28       1.370452\n",
      "29       0.989671\n",
      "           ...   \n",
      "49970    0.653691\n",
      "49971    0.446830\n",
      "49972    1.247112\n",
      "49973    0.319541\n",
      "49974    1.087259\n",
      "49975    0.151077\n",
      "49976    1.261622\n",
      "49977    0.539086\n",
      "49978    1.214174\n",
      "49979    0.435011\n",
      "49980    0.861702\n",
      "49981    0.079949\n",
      "49982    1.348423\n",
      "49983    0.689318\n",
      "49984    0.754020\n",
      "49985    0.644993\n",
      "49986    1.215291\n",
      "49987    0.472973\n",
      "49988    1.184972\n",
      "49989    0.314227\n",
      "49990    0.703893\n",
      "49991    0.972759\n",
      "49992    1.012906\n",
      "49993    0.755574\n",
      "49994    0.456649\n",
      "49995    1.895761\n",
      "49996    1.884609\n",
      "49997    0.599188\n",
      "49998    1.492266\n",
      "49999    1.248036\n",
      "Name: x3, Length: 50000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,0:2]\n",
    "Y = df.iloc[:,2]\n",
    "print(X)\n",
    "print(Y)\n",
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(2, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='adagrad')\n",
    "    return model\n",
    "\n",
    "# Creating Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.4334\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0478\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0010\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 9.0806e-05\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 3.0260e-05\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 1.5400e-05\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 9.5250e-06\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 6.5672e-06\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 4.8418e-06\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.7047e-06\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 2.9244e-06\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 2.3678e-06\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 1.9571e-06\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 1.6425e-06\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 1.3959e-06\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.2022e-06\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 1.0465e-06\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 9.1916e-07\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 8.1336e-07\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 7.2514e-07\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 6.5031e-07\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 5.8676e-07\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 5.3215e-07\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 4.8485e-07\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 4.4328e-07\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 4.0680e-07\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 3.7454e-07\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 3.4577e-07\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 3.2008e-07\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 2.9695e-07\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 2.7608e-07\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 2.5746e-07\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 2.4055e-07\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 2.2541e-07\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 2.1159e-07\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.9889e-07\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.8720e-07\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 1.7652e-07\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 1.6670e-07\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 1.5768e-07\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 1.4928e-07\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.4143e-07\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.3405e-07\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 1.2743e-07\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 1.2116e-07\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 1.1532e-07\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 1.0988e-07\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.0487e-07\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.0007e-07\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 9.5585e-08\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 9.1392e-08\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 8.7436e-08\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 8.3703e-08\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 8.0153e-08\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 7.6831e-08\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 7.3624e-08\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 7.0665e-08\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 6.7870e-08\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 6.5178e-08\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 6.2645e-08\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 6.0291e-08\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 5.8051e-08\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 5.5889e-08\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 5.3849e-08\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 5.1912e-08\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 5.0020e-08\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 4.8305e-08\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 4.6616e-08\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 4.5003e-08\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 4.3475e-08\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 4.1979e-08\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 4.0567e-08\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 3.9229e-08\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 3.7971e-08\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 3.6736e-08\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 3.5572e-08\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 3.4438e-08\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 3.3395e-08\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 3.2342e-08\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 3.1328e-08\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 3.0394e-08\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 2.9459e-08\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 2.8579e-08\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 2.7731e-08\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 2.6901e-08\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 2.6141e-08\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 2.5385e-08\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 2.4664e-08\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 2.3963e-08\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 29us/step - loss: 2.3308e-08\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 2.2657e-08\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 2.2032e-08\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 2.1456e-08\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 2.0864e-08\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 2.0328e-08\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.9779e-08\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.9270e-08\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.8790e-08\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.8292e-08\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7833e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18e3c9cf0f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=100)\n",
    "\n",
    "# Fitting the Variables to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 14us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7580970075719016e-08"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.89401025],\n",
       "       [ 1.36151111],\n",
       "       [ 1.03451836],\n",
       "       ..., \n",
       "       [ 0.59919339],\n",
       "       [ 1.49227881],\n",
       "       [ 1.24804068]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(X)\n",
    "y_pred\n",
    "\n",
    "# Predicting the target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999998942503131"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred, Y)\n",
    "\n",
    "# Checking the accuracy of the predicted values with respect to the actual values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Loss vs Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18e3e01ad68>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuyQ1kOEuSQ1kuEtSAxnuktRA/we4KINQzUdupwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18e3e01a550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(model.history.history)\n",
    "metrics_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
